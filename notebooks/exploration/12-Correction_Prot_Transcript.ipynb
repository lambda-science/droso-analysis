{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from Bio.SubsMat import MatrixInfo as matlist\n",
    "from Bio import pairwise2\n",
    "from Bio.pairwise2 import format_alignment\n",
    "from Bio.Data import CodonTable\n",
    "from Bio.Seq import translate\n",
    "import math\n",
    "import numpy as np\n",
    "def fasta2List(pathFasta):\n",
    "    f = open(pathFasta, \"r\")\n",
    "    title = []\n",
    "    seq = []\n",
    "    seq_temp = []\n",
    "    for line in f:\n",
    "        if line[0] == \">\":\n",
    "            seq.append(''.join(seq_temp).replace(\"\\n\", \"\"))\n",
    "            title.append(line.replace(\"\\n\", \"\"))\n",
    "            seq_temp = []\n",
    "        else:\n",
    "            seq_temp.append(line)\n",
    "    seq.append(''.join(seq_temp).replace(\"\\n\", \"\"))\n",
    "    seq.pop(0)\n",
    "    dictionary = dict(zip(title, seq))\n",
    "    return dictionary\n",
    "\n",
    "conn = sqlite3.connect('../../mismatch_db.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch = pd.read_sql_query(\"SELECT * FROM mismatch\", conn)\n",
    "mismatch = mismatch.astype({\"exon_start_prim\": \"Int64\", \"exon_stop_prim\":\"Int64\", \"exon_start_hum\": \"Int64\", \"exon_stop_hum\":\"Int64\"})\n",
    "\n",
    "prim_exon_introns = pd.read_sql_query(\"\"\"\n",
    "SELECT mismatch_ID, mismatch.prot_prim, exon_intron_map.'type', exon_intron_map.number_elem, exon_intron_map.seq\n",
    "FROM mismatch\n",
    "JOIN protein ON mismatch.prot_prim = protein.prot_ID\n",
    "JOIN transcript ON protein.transcript_ID = transcript.transcript_ID\n",
    "JOIN exon_intron_map ON transcript.transcript_ID = exon_intron_map.transcript_ID\n",
    "\"\"\", conn)\n",
    "\n",
    "mismatch_prot_transcript = pd.read_sql_query(\n",
    "\"\"\"SELECT * \n",
    "FROM mismatch\n",
    "JOIN protein ON mismatch.prot_prim = protein.prot_ID\n",
    "JOIN transcript ON protein.transcript_ID = transcript.transcript_ID\"\"\", conn)\n",
    "\n",
    "mismatch_to_correct = pd.read_sql_query(\n",
    "\"\"\"SELECT mismatch.*\n",
    "FROM mismatch_flag \n",
    "JOIN tblastn_match ON mismatch_flag.mismatch_ID = tblastn_match.mismatch_ID \n",
    "JOIN mismatch on mismatch_flag.mismatch_ID = mismatch.mismatch_ID \n",
    "WHERE (one_hum_multiple_prim = 1\n",
    "OR non_canonical_hum_spl = 1\n",
    "OR N_in_genomic = 1\n",
    "OR small_introns = 1)\n",
    "AND conserved = 0\n",
    "AND repeats_prot = 0\n",
    "AND alignement_error = 0\n",
    "AND human_isoform_exist = 0\n",
    "\"\"\", conn)\n",
    "\n",
    "tblastn = pd.read_sql_query(\n",
    "\"\"\"SELECT tblastn_match.*\n",
    "FROM tblastn_match \n",
    "JOIN mismatch_flag ON mismatch_flag.mismatch_ID = tblastn_match.mismatch_ID \n",
    "WHERE (one_hum_multiple_prim = 1\n",
    "OR non_canonical_hum_spl = 1\n",
    "OR N_in_genomic = 1\n",
    "OR small_introns = 1)\n",
    "AND conserved = 0\n",
    "AND repeats_prot = 0\n",
    "AND alignement_error = 0\n",
    "AND human_isoform_exist = 0\n",
    "\"\"\", conn)\n",
    "\n",
    "protein_df = pd.read_sql_query(\n",
    "\"\"\"SELECT * \n",
    "FROM protein\n",
    "\"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MSEREERRFVEIPRESVRLMAESTGLELSDEVAALLAEDVCYRLREATQNSSQFMKHTKRRKLTVEDFNRALRWSSVEAVCGYGSQEALPMRPAREGELYFPEDREVNLVELALATNIPKGCAETAVRVHVSYLDGKGNLAPQGSVPSAVSSLTDDLLKYYHQVTRAVLGDDPQLMKVALQDLQTNSKIGALLPYFVYVVSGVKSVSHDLEQLHRLLQVARSLFRNPHLCLGPYVRCLVGSVLYCVLEPLAASINPLNDHWTLRDGAALLLSHIFWTHGDLVSGLYQHILLSLQKILADPVRPLCCHYGAVVGLHALGWKAVERVLYPHLSTYWTNLQAVLDDYSVSNAQVKADGHKVYGAILVAVERLLKMKAQAAEPNRGGPGGRGCRRLDDLPWDSLLFQESSSGGGAEPSFGSGLPLPPGGAGPEDPSLSVTLADIYRELYAFFGDSLATRFGTGQPAPTAPRPPGDKKEPAAAPDSVRKMPQLTASAIVSPHGDESPRGSGGGGPASASGPAASESRPLPRVHRARGAPRQQGPGTGTRDVFQKSRFAPRGAPHFRFIIAGRQAGRRCRGRLFQTAFPAPYGPSPASRYVQKLPMIGRTSRPARRWALSDYSLYLPL'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_df.loc[protein_df[\"prot_ID\"] == row[1]].iloc[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/meyer/anaconda3/envs/stage-env/lib/python3.7/site-packages/ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/meyer/anaconda3/envs/stage-env/lib/python3.7/site-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# SCRIPT DE CORRECTION DES MISMATCH\n",
    "total = 0\n",
    "error_big = 0\n",
    "error_fus = 0\n",
    "error_fus3 = 0\n",
    "total_OK = 0\n",
    "codon_stop = 0\n",
    "bug_bizarre = 0\n",
    "\n",
    "for index, row in mismatch_to_correct.iloc[:,:].iterrows():\n",
    "    transcript_map = prim_exon_introns.loc[(prim_exon_introns[\"mismatch_ID\"] == int(row[0])) & (prim_exon_introns[\"type\"] == \"Exon\")]\n",
    "    id_exon_start = row[7]-1\n",
    "    id_exon_stop = row[8]\n",
    "    mismatch_peptid = row[11]\n",
    "    \n",
    "    # LOCALISATION EXACT DES MISMATCH\n",
    "    mismatch_exon_table = transcript_map.iloc[id_exon_start:id_exon_stop]\n",
    "    mismatch_exon = transcript_map.iloc[id_exon_start:id_exon_stop, 4]\n",
    "    exon_seq = mismatch_exon.str.cat(sep=\"\")\n",
    "    for i in range(3):\n",
    "        peptid = translate(exon_seq[i:])\n",
    "        frame = i\n",
    "        match_find = peptid.find(row[11])\n",
    "        if match_find != -1:\n",
    "            break\n",
    "    start_nuc_mismatch = match_find*3+frame\n",
    "    stop_nuc_mismatch = match_find*3+len(mismatch_peptid*3)+frame\n",
    "    \n",
    "    # CREATION DES COORDONEE NUCLEOTIDES DES EXONS A MISMATCH\n",
    "    taille_exon = []\n",
    "    for index2, row2 in mismatch_exon_table.iloc[:,:].iterrows():\n",
    "        taille_exon.append(len(row2[4]))\n",
    "    taille_exon_fin = [sum(taille_exon[:x+1]) for x in range(0,len(taille_exon))]\n",
    "    taille_exon_debut = taille_exon_fin.copy()\n",
    "    taille_exon_debut.pop()\n",
    "    taille_exon_debut[:]=[i+1 for i in taille_exon_debut]\n",
    "    taille_exon_debut.insert(0, 0)\n",
    "    mismatch_exon_table[\"pos_start\"] = taille_exon_debut\n",
    "    mismatch_exon_table[\"pos_stop\"] = taille_exon_fin\n",
    "    \n",
    "    # SUPPRESSION DES PARTIE D'EXON DES TRANSCRIPT\n",
    "    exon_seq = transcript_map.iloc[:, 4].str.cat(sep=\"\")\n",
    "    #print(transcript_map)\n",
    "    #print(translate(exon_seq[:]))\n",
    "    #print(\"*\")\n",
    "    #print(row[0])\n",
    "    #print(frame)\n",
    "    #print(\"*\")\n",
    "    for index2, row2 in mismatch_exon_table.iloc[:,:].iterrows():\n",
    "        if row2[5] >= start_nuc_mismatch and row2[6] <= stop_nuc_mismatch:\n",
    "            #print(\"TO DELETE TOTALLY\", row2[3], index)\n",
    "            conditional_index = transcript_map.loc[ transcript_map['number_elem'] == row2[3] ].index\n",
    "            transcript_map.loc[conditional_index, [\"seq\"]] = \"\"\n",
    "\n",
    "        if row2[5] < start_nuc_mismatch and row2[6] < stop_nuc_mismatch:\n",
    "            #print(\"DELETE THE END OF EXON\", row2[3])\n",
    "            conditional_index = transcript_map.loc[ transcript_map['number_elem'] == row2[3] ].index\n",
    "            suppr = transcript_map.loc[conditional_index, \"seq\"].iloc[0][start_nuc_mismatch-row2[5]:]\n",
    "            transcript_map.loc[conditional_index, [\"seq\"]] = transcript_map.loc[conditional_index, \"seq\"].iloc[0][:start_nuc_mismatch-row2[5]]\n",
    "        if row2[5] > start_nuc_mismatch and row2[6] > stop_nuc_mismatch:\n",
    "            #print(\"DELETE THE BEGIN OF EXON\", row2[3])\n",
    "            conditional_index = transcript_map.loc[ transcript_map['number_elem'] == row2[3] ].index\n",
    "            suppr += transcript_map.loc[conditional_index, \"seq\"].iloc[0][:stop_nuc_mismatch-row2[5]+1]\n",
    "            transcript_map.loc[conditional_index, [\"seq\"]] = transcript_map.loc[conditional_index, \"seq\"].iloc[0][stop_nuc_mismatch-row2[5]+1:]\n",
    "\n",
    "        if row2[5] <= start_nuc_mismatch and row2[6] >= stop_nuc_mismatch:\n",
    "            # 1er nvx exon \n",
    "            conditional_index = transcript_map.loc[ transcript_map['number_elem'] == row2[3] ].index\n",
    "            transcript_map.loc[conditional_index, [\"seq\"]] = transcript_map.loc[conditional_index, \"seq\"].iloc[0][:start_nuc_mismatch-row2[5]]\n",
    "            # 2e nvx exon exon X.5\n",
    "            new_row = row2.copy()\n",
    "            new_row[3] = new_row[3] + 0.5\n",
    "            new_row[4] = new_row[4][stop_nuc_mismatch-new_row[5]:]\n",
    "            row_df = pd.DataFrame(new_row)\n",
    "            if len(row_df.index) > 1: row_df = row_df.T\n",
    "            transcript_map = pd.concat([transcript_map, row_df], ignore_index=True)\n",
    "            conditional_index = transcript_map.loc[ transcript_map['number_elem'] == row2[3]+0.5 ].index\n",
    "            \n",
    "    # CORRECTION\n",
    "    myTblastnMatch = tblastn.loc[ tblastn[\"mismatch_ID\"] == row[0] ]\n",
    "    \n",
    "    try:\n",
    "        prim_exon = prim_exon_introns.loc[(prim_exon_introns[\"mismatch_ID\"]==row[0]) & (prim_exon_introns[\"number_elem\"].isin(range(row[7],row[8]+1))) & (prim_exon_introns[\"type\"]==\"Exon\")]\n",
    "        prim_intron = prim_exon_introns.loc[(prim_exon_introns[\"mismatch_ID\"]==row[0]) & (prim_exon_introns[\"number_elem\"].isin(range(row[7],row[8]))) & (prim_exon_introns[\"type\"]==\"Intron\")]\n",
    "    except:\n",
    "        print(\"Error transcript\")\n",
    "    genomic_Seq = \"\"\n",
    "    for i in range(0,row[8]+1-row[7]):\n",
    "        genomic_Seq += prim_exon.iloc[i,4]\n",
    "        try: genomic_Seq += prim_intron.iloc[i,4]\n",
    "        except: pass\n",
    "    tblastn_dna = genomic_Seq[myTblastnMatch.iloc[0, 5]+2:myTblastnMatch.iloc[0, 6]]\n",
    "    \n",
    "    # Splicing site check\n",
    "    no_splicing_site = False\n",
    "    splicing_5_pos = -1\n",
    "    finish_splicing = False\n",
    "    loop_value = [0, 1, 2, -1, -2]\n",
    "    for i in loop_value:\n",
    "        splicing_5 = genomic_Seq[myTblastnMatch.iloc[0, 5]-i*3:myTblastnMatch.iloc[0, 5]+2-i*3]\n",
    "        if  splicing_5 == \"AG\":\n",
    "            new_start = myTblastnMatch.iloc[0, 5]+2-i*3\n",
    "            for j in loop_value:\n",
    "                splicing_3 = genomic_Seq[myTblastnMatch.iloc[0, 6]+i*3:myTblastnMatch.iloc[0, 6]+2+i*3]\n",
    "                if  splicing_3 == \"GT\":\n",
    "                    new_stop = myTblastnMatch.iloc[0, 6]+i*3\n",
    "                    tblastn_dna = genomic_Seq[new_start:new_stop]\n",
    "                    finish_splicing = True\n",
    "                    break\n",
    "        if finish_splicing: break\n",
    "        else:\n",
    "            no_splicing_site = True\n",
    "    \n",
    "    if no_splicing_site: continue\n",
    "    \n",
    "    new_row_blast = row2.copy()\n",
    "    new_row_blast[3] = row[7] + 0.25\n",
    "    new_row_blast[4] = tblastn_dna\n",
    "    if \"*\" in translate(tblastn_dna): \n",
    "        continue\n",
    "    row_df_blast = pd.DataFrame(new_row_blast[:-2])\n",
    "    if len(row_df_blast.index) > 1: row_df_blast = row_df_blast.T\n",
    "    transcript_map = pd.concat([transcript_map, row_df_blast], ignore_index=True)\n",
    "\n",
    "    transcript_map = transcript_map[transcript_map['seq'].map(len) > 0]\n",
    "    transcript_map.sort_values(by=\"number_elem\", inplace=True, ignore_index=True)\n",
    "    transcript_map[\"number_elem\"] = range(1, len(transcript_map.index)+1)\n",
    "    exon_seq = transcript_map.iloc[:, 4].str.cat(sep=\"\")\n",
    "    \n",
    "    # VERIFIER QUE LE TRANSCRIPT S'ENCHAINE BIEN\n",
    "    exon_start = []\n",
    "    exon_stop = []\n",
    "    genomic = mismatch_prot_transcript.loc[mismatch_prot_transcript[\"mismatch_ID\"]== row[0] ].iloc[0, 19]\n",
    "    for index3, row3 in transcript_map.iloc[:,:].iterrows():\n",
    "        exon_start.append(genomic.find(row3[4]))\n",
    "        exon_stop.append(genomic.find(row3[4])+len(row3[4]))\n",
    "    transcript_map[\"exon_start\"] = exon_start\n",
    "    transcript_map[\"exon_stop\"] = exon_stop\n",
    "    \n",
    "    \n",
    "    total +=1\n",
    "    Error_switch = False\n",
    "    for i in range(len(transcript_map.index)-1):\n",
    "        if transcript_map.iloc[i, 6] > transcript_map.iloc[i+1, 5]:\n",
    "            if transcript_map.iloc[i, 6]-transcript_map.iloc[i+1, 5] > 15 and len(transcript_map.iloc[i, 4])>=17 and len(transcript_map.iloc[i+1, 4])>=17:\n",
    "                #print(\"Big error\")\n",
    "                #print(transcript_map.iloc[i, 4], len(transcript_map.iloc[i, 4]))\n",
    "                #print(transcript_map.iloc[i+1, 4], len(transcript_map.iloc[i+1, 4]))\n",
    "                error_big += 1\n",
    "                Error_switch = True\n",
    "                break\n",
    "            elif transcript_map.iloc[i, 6]-transcript_map.iloc[i+1, 5] <= 15 and len(transcript_map.iloc[i, 4])>=17 and len(transcript_map.iloc[i+1, 4])>=17:\n",
    "                #print(\"Fusion issue\")\n",
    "                #print(transcript_map.iloc[i, 6]-transcript_map.iloc[i+1, 5])\n",
    "                if (transcript_map.iloc[i, 6]-transcript_map.iloc[i+1, 5])%3 == 0: error_fus3 +=1\n",
    "                error_fus += 1\n",
    "                Error_switch = True\n",
    "                break\n",
    "    if Error_switch == True: continue\n",
    "    total_OK += 1\n",
    "    \n",
    "    # TRADUCTION DE PROT\n",
    "    # Mapping de l'ancienne CDS\n",
    "    old_cds = mismatch_prot_transcript.loc[mismatch_prot_transcript[\"mismatch_ID\"]== row[0] ].iloc[0, 18]\n",
    "    start_tri = exon_seq.find(old_cds[:45])\n",
    "    \n",
    "    # Si mapping foire on cherche la plus grand CDS contenant notre correction\n",
    "    if start_tri == -1:\n",
    "        frame = \"Error\"\n",
    "        start = []\n",
    "        stop = []\n",
    "        CDS = []\n",
    "        for i in range(3):\n",
    "            prot_seq = translate(exon_seq[i:])\n",
    "            if translate(tblastn_dna) in prot_seq:\n",
    "                frame = i\n",
    "                break\n",
    "        correction = prot_seq.find(translate(tblastn_dna))\n",
    "        if correction == -1: print(\"Error could not find tlbastn match in prot\")\n",
    "        old_prot = mismatch_prot_transcript.loc[mismatch_prot_transcript[\"mismatch_ID\"]== row[0] ].iloc[0, 14]\n",
    "        furthest_start = -1\n",
    "        stop_pos = -1\n",
    "        first_AA = -1\n",
    "        for i in range(correction,0,-1):\n",
    "            if prot_seq[i] == \"M\":\n",
    "                furthest_start = i\n",
    "            if prot_seq[i] == \"*\":\n",
    "                stop_pos = i\n",
    "                break\n",
    "        if furthest_start == -1 and stop_pos == -1: first_AA = 0\n",
    "        elif stop_pos < furthest_start: first_AA = furthest_start\n",
    "        elif stop_pos > furthest_start: first_AA = stop_pos+1\n",
    "\n",
    "        prot_seq = prot_seq[first_AA:]\n",
    "        stop_codon = prot_seq.find(\"*\")\n",
    "        if stop_codon != -1: prot_seq = prot_seq[:stop_codon]\n",
    "    \n",
    "    # Sinon si le mapping à fonctionné, on crée la prot.\n",
    "    else: \n",
    "        prot_seq = translate(exon_seq[start_tri:])\n",
    "        # Bug bizarre sur 3 prot pour 600 qui n'ont pas pu etre corrigé au final ? A voir\n",
    "        if translate(tblastn_dna) not in prot_seq:\n",
    "            bug_bizarre += 1\n",
    "            continue\n",
    "        \n",
    "        stop_codon = prot_seq.find(\"*\")\n",
    "        if stop_codon != -1: prot_seq = prot_seq[:stop_codon]\n",
    "\n",
    "  \n",
    "    #f = open(\"../../data/correction/two-by-two2/\"+str(row[0])+\"_\"+row[1]+\"_\"+row[2]+\".fasta\", \"w\")\n",
    "    f = open(\"../../data/correction/two-by-two2/\"+row[1]+\"_\"+row[2]+\".fasta\", \"w\")\n",
    "    f.write(\">\"+row[1]+\"\\n\")\n",
    "    f.write(protein_df.loc[protein_df[\"prot_ID\"] == row[1]].iloc[0, 1]+\"\\n\")\n",
    "    f.write(\">\"+row[2]+\"\\n\")\n",
    "    f.write(prot_seq+\"\\n\")\n",
    "    f.close()\n",
    "    \n",
    "    #f = open(\"../../data/correction/two-by-two-old2/\"+str(row[0])+\"_\"+row[1]+\"_\"+row[2]+\".fasta\", \"w\")\n",
    "    f = open(\"../../data/correction/two-by-two-old2/\"+row[1]+\"_\"+row[2]+\".fasta\", \"w\")\n",
    "    f.write(\">\"+row[1]+\"\\n\")\n",
    "    f.write(protein_df.loc[protein_df[\"prot_ID\"] == row[1]].iloc[0, 1]+\"\\n\")\n",
    "    f.write(\">\"+row[2]+\"\\n\")\n",
    "    f.write(protein_df.loc[protein_df[\"prot_ID\"] == row[2]].iloc[0, 1]+\"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from Bio import AlignIO\n",
    "import numpy as np\n",
    "\n",
    "identity_score = []\n",
    "old_identity_score = []\n",
    "coverage = []\n",
    "old_coverage = []\n",
    "\n",
    "alignements_files = glob.glob('../../data/correction/two-by-two/*.mafft')\n",
    "alignements_files_old = glob.glob('../../data/correction/two-by-two-old/*.mafft')\n",
    "for files_id in range(len(alignements_files)):\n",
    "    identity = 0\n",
    "    old_identity = 0\n",
    "    no_gap = 0\n",
    "    no_gap_old = 0\n",
    "    \n",
    "    align = AlignIO.read(alignements_files[files_id], \"fasta\")\n",
    "    for i in range(align.get_alignment_length()):\n",
    "        if align[0][i] != \"-\" and align[1][i] != \"-\":\n",
    "            no_gap += 1\n",
    "        if align[0][i] == align[1][i]:\n",
    "            identity += 1\n",
    "    #identity_score.append(identity/align.get_alignment_length()*100)\n",
    "    identity_score.append(identity/no_gap*100)\n",
    "    coverage.append(no_gap/align.get_alignment_length()*100)\n",
    "    \n",
    "    align_old = AlignIO.read(alignements_files_old[files_id], \"fasta\")\n",
    "    for i in range(align_old.get_alignment_length()):\n",
    "        if align_old[0][i] != \"-\" and align_old[1][i] != \"-\":\n",
    "            no_gap_old += 1\n",
    "        if align_old[0][i] == align_old[1][i]:\n",
    "            old_identity += 1\n",
    "    #old_identity_score.append(old_identity/align_old.get_alignment_length()*100)\n",
    "    old_identity_score.append(old_identity/no_gap_old*100)\n",
    "    old_coverage.append(no_gap_old/align_old.get_alignment_length()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "91.95625264796031\n95.09021328329614\n89.40449282382119\n90.67656818986796\n"
    }
   ],
   "source": [
    "print(np.mean(old_identity_score))\n",
    "print(np.mean(identity_score))\n",
    "print(np.mean(old_coverage))\n",
    "print(np.mean(coverage))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('stage-env': conda)",
   "language": "python",
   "name": "python37664bitstageenvconda39052ae7dd75404f9bdb3226673ac6d7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}