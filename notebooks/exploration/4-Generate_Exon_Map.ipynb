{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script permettant de générer la carte exonique (exon map) des gènes d'intérêt\n",
    "Input: le json file génnéré à partir des réponse API Ensemble Lookup. Plusieurs réponse peuvent être dans un seul json, une par ligne, le json est mergé.  \n",
    "Output: exon_map.tab fichier texte tabulation contenant la position de chaque exon et la séquence pour chaque transcript d'intérêt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les données: json + correspondance uniprot/refseq + genomic\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Pour merger les json entre eux\n",
    "def merge_two_dicts(x, y):\n",
    "    z = x.copy()\n",
    "    z.update(y)    \n",
    "    return z\n",
    "\n",
    "# Pour importer les json\n",
    "def importJson(filePath):\n",
    "    data_dict = []\n",
    "    with open(filePath) as json_data:\n",
    "        for i in json_data:\n",
    "            data_dict.append(json.loads(i))\n",
    "    MyJsonFull = data_dict[0]\n",
    "    for i in data_dict[1:]:\n",
    "        MyJsonFull = merge_two_dicts(MyJsonFull, i)\n",
    "    return MyJsonFull\n",
    "\n",
    "# Renvoie une string contenant la ligne à écrire dans le fichier (position exon, séquence...)\n",
    "def catExonPos(MyJsonFull, seqID, dict_Genomic):\n",
    "    exonString = []\n",
    "    if MyJsonFull[seqID][\"strand\"] == -1:\n",
    "        ABSOLUTE_POST = MyJsonFull[seqID][\"end\"]\n",
    "        exon_list = MyJsonFull[seqID][\"Exon\"]\n",
    "        counter = 1\n",
    "        for i in exon_list:\n",
    "            stop = str(abs(i['end']-ABSOLUTE_POST))\n",
    "            start = str(abs(i['start']-ABSOLUTE_POST)+1)\n",
    "            res = [val for key, val in my_Genomic.items() if seqID in key]\n",
    "            exonString.append(seqID+ \"\\tExon\\t\"+str(counter)+\"\\t\"+stop+\"\\t\"+start+\"\\t\"+res[0][int(stop):int(start)])\n",
    "            counter+=1\n",
    "\n",
    "    if MyJsonFull[seqID][\"strand\"] == 1:\n",
    "        ABSOLUTE_POST = MyJsonFull[seqID][\"start\"]\n",
    "        exon_list = MyJsonFull[seqID][\"Exon\"]\n",
    "        counter = 1\n",
    "        for i in exon_list:\n",
    "            start = str(abs(i['start']-ABSOLUTE_POST))\n",
    "            stop = str(abs(i['end']-ABSOLUTE_POST)+1)\n",
    "            res = [val for key, val in dict_Genomic.items() if seqID in key]\n",
    "            exonString.append(seqID+ \"\\tExon\\t\"+str(counter)+\"\\t\"+start+\"\\t\"+stop+\"\\t\"+res[0][int(start):int(stop)])\n",
    "            counter+=1\n",
    "    return(exonString)\n",
    "\n",
    "# Importe un fichier fasta en dictionnaire titre:séquence\n",
    "def fasta2List(pathFasta):\n",
    "    f = open(pathFasta, \"r\")\n",
    "    title = []\n",
    "    seq = []\n",
    "    seq_temp = []\n",
    "    for line in f:\n",
    "        if line[0] == \">\":\n",
    "            seq.append(''.join(seq_temp).replace(\"\\n\", \"\"))\n",
    "            title.append(line.replace(\"\\n\", \"\"))\n",
    "            seq_temp = []\n",
    "        else:\n",
    "            seq_temp.append(line)\n",
    "    seq.append(''.join(seq_temp).replace(\"\\n\", \"\"))\n",
    "    seq.pop(0)\n",
    "    dictionary = dict(zip(title, seq))\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/mismatch-analysis/lookup_newline.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-36d7b2132b41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mID_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../data/mismatch-analysis/uniprot-exon-map/transcript_ensembl.tab\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mjsonFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportJson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../data/mismatch-analysis/lookup_newline.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmy_Genomic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfasta2List\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../data/mismatch-analysis/genomics_new.fa\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-08f5e8532c53>\u001b[0m in \u001b[0;36mimportJson\u001b[0;34m(filePath)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimportJson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdata_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilePath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mdata_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/mismatch-analysis/lookup_newline.json'"
     ]
    }
   ],
   "source": [
    "ID_file = pd.read_csv(\"../../data/mismatch-analysis/uniprot-exon-map/transcript_ensembl.tab\", sep = \"\\t\")\n",
    "jsonFile = importJson('../../data/mismatch-analysis/lookup_newline.json')\n",
    "my_Genomic = fasta2List(\"../../data/mismatch-analysis/genomics_new.fa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/mismatch-analysis/uniprot-exon-map/Exon_map.tab\", \"w\") as exon_file:\n",
    "    for i in ID_file.iloc[:,1]:\n",
    "        uniprot_name = ID_file.loc[ID_file[\"To\"] == i].iloc[0,0]\n",
    "        for exon in catExonPos(jsonFile, i, my_Genomic):\n",
    "            exon_file.write(uniprot_name+\"\\t\"+exon+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On fait maintenant l'intron map pour trouver les petits introns\n",
    "Exon_Map = pd.read_csv(\"../../data/mismatch-analysis/uniprot-exon-map/Exon_map.tab\", sep=\"\\t\", header=None)\n",
    "protein_list = list(set(Exon_Map.iloc[:,0].to_list()))\n",
    "\n",
    "Intron_Map_light = open(\"../../data/mismatch-analysis/uniprot-exon-map/Intron_map_light.tab\", \"w\")\n",
    "\n",
    "for prot in protein_list:\n",
    "    subset = Exon_Map.loc[Exon_Map[0]==prot]\n",
    "    intron_number = len(subset.index)-1\n",
    "    for i in range(intron_number):\n",
    "        intron_start = str(int(subset.iloc[i,5]))\n",
    "        intron_stop = str(int(subset.iloc[i+1,4]))\n",
    "        ensembl_ID = str(subset.iloc[i,1])\n",
    "        Intron_Map_light.write(prot+\"\\t\"+ensembl_ID+\"\\tIntron\\t\"+str(i+1)+\"\\t\"+intron_start+\"\\t\"+intron_stop+\"\\n\")\n",
    "\n",
    "Intron_Map_light.close()"
   ]
  }
 ]
}