{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Script permettant de récupérer les Json Orthoinspector et d'obtenir un fichier par protéine humaine avec les identifiant Uniprot des protéines ortologue pour chaque protéine (humaine et primate)\n",
    "Input: aucun  \n",
    "Output:  \n",
    "    Stockage des réponse Json Orthoinspector  \n",
    "    Stockage du processing des json avec un fichie par espèce contenant les protéines ID  \n",
    "    Stockage d'un unique tableau contenant en colonne chaque espèce et en ligne chaque protéine ID  \n",
    "    Stockage d'un fichier par ligne contenant l'ID humain et les ID de chaque primate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Récupérer les fichiers json qui listent tout les ortholgoues entre humain et espèce d'intérêt \n",
    "taxonID=(60711 9541 9544 9555 9595 9598 9601 61853 9483 30611)\n",
    "name=(C.sabaeus M.fascicularis M.mulatta P.anubis G.gorilla H.sapiens P.troglodytes P.abellii N.leucogenys C.jacchus O.garnettii)\n",
    "human=9606\n",
    "for i in ${taxonID[@]}\n",
    "do\n",
    "    curl -X GET \"https://lbgi.fr/orthoinspectorv3/api/Eukaryota/species/$human/orthologs/$i\" -H  \"accept: application/json\" > ../raw/orthoinspector_json/$i.json\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traiter les fichiers json pour avoir un colonne prot humaine et une colonne orthologue chez espèce d'intérêt\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "\n",
    "\n",
    "taxonID = [60711, 9541, 9544, 9555, 9595, 9598, 9601, 61853, 9483, 30611]\n",
    "human = 9606\n",
    "\n",
    "myfiles = listdir(\"../raw/orthoinspector_json/\")\n",
    "for i in range(10):\n",
    "    f = open(\"../raw/orthoinspector_json-processed/\"+str(taxonID[i])+\".txt\", \"w\")\n",
    "    with open(\"../raw/orthoinspector_json/\"+str(taxonID[i])+\".json\") as json_file:\n",
    "        data = json.load(json_file)\n",
    "        f.write(\"9606\\t\"+str(taxonID[i])+\"\\n\")\n",
    "        for human_prot in data:\n",
    "            if human_prot == data[human_prot]['orthologs'][0]:\n",
    "                f.write(human_prot+\"\\t\"+ str(\"NaN\"+\"\\n\"))\n",
    "            else:\n",
    "                f.write(human_prot+\"\\t\"+ str(data[human_prot]['orthologs'][0]+\"\\n\"))\n",
    "            #f.write((human_prot+\"\\t\"+ ' '.join([i for i in data[human_prot]['orthologs']])+\"\\n\"))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Species\n",
    "\t\n",
    "Taxon\n",
    "\t\n",
    "Model\n",
    "\t\n",
    "NCBI Taxonomy id\n",
    "Chlorocebus sabaeus \tMetazoa \t\t60711\n",
    "Macaca fascicularis \tMetazoa \t\t9541\n",
    "Macaca mulatta \tMetazoa \t\t9544\n",
    "Papio anubis \tMetazoa \t\t9555\n",
    "Gorilla gorilla gorilla \tMetazoa \t\t9595\n",
    "Homo sapiens \tMetazoa \t\t9606\n",
    "Pan troglodytes \tMetazoa \t\t9598\n",
    "Pongo abelii \tMetazoa \t\t9601\n",
    "Nomascus leucogenys \tMetazoa \t\t61853\n",
    "Callithrix jacchus \tMetazoa \t\t9483\n",
    "Otolemur garnettii \tMetazoa \t\t30611"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fusion des fichier traiter précédent pour passer d'un fichier par comparaison à un fichier pour toute les comparaison\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "\n",
    "myfiles2 = listdir(\"../raw/orthoinspector_json-processed/\")\n",
    "main_df = pd.read_csv('../raw/orthoinspector_json-processed/'+myfiles2[0], sep='\\t', header=0)\n",
    "for i in range(1, 10):\n",
    "    df_temp = pd.read_csv('../raw/orthoinspector_json-processed/'+myfiles2[i], sep='\\t', header=0)\n",
    "    main_df = main_df.merge(df_temp, on=\"9606\", how=\"outer\")\n",
    "gene_names = main_df.copy()\n",
    "gene_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gene_names.to_csv(\"../raw/orthoinspector_json-processed/allProteineName.txt\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des identifiants pour query de séquence par fichier. Un fichier par comparaison (20 000 au total) à récupérer\n",
    "# Une séquence par ligne\n",
    "for i in range(20265):\n",
    "    f = open(\"../raw/uniprot-sequence/\"+str(gene_names.iloc[i,0])+\".id\", \"w\", newline='\\n')\n",
    "    query = gene_names.iloc[i,:].dropna().tolist()\n",
    "    query = ' '.join(query)\n",
    "    query = query.split(\" \")\n",
    "    for i in query:\n",
    "        f.write(str(i)+\"\\n\")\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}