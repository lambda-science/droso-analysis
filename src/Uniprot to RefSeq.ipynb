{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Fusion des fichier traiter précédent pour passer d'un fichier par comparaison à un fichier pour toute les comparaison\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "\n",
    "myfiles2 = listdir(\"json-processed/\")\n",
    "main_df = pd.read_csv('json-processed/'+myfiles2[0], sep='\\t', header=0)\n",
    "for i in range(1, 10):\n",
    "    df_temp = pd.read_csv('json-processed/'+myfiles2[i], sep='\\t', header=0)\n",
    "    main_df = main_df.merge(df_temp, on=\"9606\", how=\"outer\")\n",
    "gene_names = main_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "Entrez.email = \"corentin.meyer@etu.unistra.fr\"\n",
    "uni_gene_name = pd.read_csv(\"human_gene_name.txt\", sep=\"\\t\")\n",
    "species=[\"Homo sapiens\", \"Otolemur garnettii\", \"Chlorocebus sabaeus\", \"Nomascus leucogenys\", \"Callithrix jacchus\",\n",
    "         \"Macaca fascicularis\", \"Macaca mulatta\", \"Papio anubis\", \"Gorilla gorilla gorilla\",\n",
    "          \"Pan troglodytes\", \"Pongo abelii\"]\n",
    "\n",
    "##### Récupération du RefSeq ID à partir du Gene Name et de l'organisme d'intérêt\n",
    "for i in uni_gene_name.iloc[:2,1]:\n",
    "    #f = open(i+\".id\", \"a\"):\n",
    "    for j in species:\n",
    "        try:\n",
    "            handle = Entrez.esearch(db=\"protein\", term=i+\" \"+j, retmax=1)\n",
    "            record = Entrez.read(handle)\n",
    "            handle.close()\n",
    "            #f.write(record[\"IdList\"][0]+\"\\n\")\n",
    "            print(record)\n",
    "        except:\n",
    "            pass\n",
    "    #f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term = uni_gene_name.iloc[:,1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests \n",
    "URL = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch\"\n",
    "\n",
    "##### Récupération du RefSeq ID à partir du Gene Name et de l'organisme d'intérêt\n",
    "#for j in range(1):\n",
    "term = uni_gene_name.iloc[:100,1].tolist()\n",
    "term = [mygene + \" \" + species[j] for mygene in term]\n",
    "myobj = {\n",
    "    \"retmax\":1,\n",
    "    \"db\":\"protein\",\n",
    "    \"term\":\"TONSL Homo sapiens\"\n",
    "}\n",
    "x = requests.post(URL, data=myobj)\n",
    "print(x.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "Entrez.email = \"corentin.meyer@etu.unistra.fr\"\n",
    "uni_gene_name = pd.read_csv(\"human_gene_name.txt\", sep=\"\\t\")\n",
    "species=[\"Homo sapiens\", \"Otolemur garnettii\", \"Chlorocebus sabaeus\", \"Nomascus leucogenys\", \"Callithrix jacchus\",\n",
    "         \"Macaca fascicularis\", \"Macaca mulatta\", \"Papio anubis\", \"Gorilla gorilla gorilla\",\n",
    "          \"Pan troglodytes\", \"Pongo abelii\"]\n",
    "\n",
    "##### Récupération du RefSeq ID à partir du Gene Name et de l'organisme d'intérêt\n",
    "for j in species:\n",
    "    print(\"Processing \"+j)\n",
    "    f = open(\"results/\"+j+\".id\", \"w\")\n",
    "    for i in uni_gene_name.iloc[:,1]:\n",
    "        try:\n",
    "            handle = Entrez.esearch(db=\"protein\", term=i+\" \"+j, retmax=1)\n",
    "            record = Entrez.read(handle)\n",
    "            handle.close()\n",
    "            f.write(record[\"IdList\"][0]+\"\\n\")\n",
    "        except:\n",
    "            f.write(\"Not Found - Error\\n\")\n",
    "            pass\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "myfiles2 = listdir(\"uniprot-mapping/\")\n",
    "main_df = pd.read_csv('json-processed/'+myfiles2[0]+\".txt\", sep='\\t', header=0)\n",
    "for i in range(1, 10):\n",
    "    df_temp = pd.read_csv('json-processed/'+myfiles2[i]+\".txt\", sep='\\t', header=0)\n",
    "    main_df = main_df.merge(df_temp, on=\"9606\", how=\"outer\")\n",
    "gene_names = main_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfiles2.pop(11)\n",
    "myfiles2.pop(11)\n",
    "myfiles2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in myfiles2:\n",
    "    temp = pd.read_csv(\"uniprot-mapping/\"+i, sep=\"\\t\")\n",
    "    temp.columns = [i, i+\"_RefSeq\"]\n",
    "    temp = temp.groupby([i]).agg(lambda col: ' '.join(col))\n",
    "    temp = pd.DataFrame(temp)\n",
    "    gene_names = gene_names.merge(temp, right_on=i, left_on=i, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonID = [9606, 60711, 9541, 9544, 9555, 9595, 9598, 9601, 61853, 9483, 30611]\n",
    "taxonID = [str(i)+\"_RefSeq_x\" for i in taxonID]\n",
    "taxonID.insert(0, \"9606\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "taxonID = [9606, 60711, 9541, 9544, 9555, 9595, 9598, 9601, 61853, 9483, 30611]\n",
    "taxonID = [str(i)+\"_RefSeq_x\" for i in taxonID]\n",
    "taxonID.insert(0, \"9606\")\n",
    "main_df = gene_names.iloc[:, [0, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]]\n",
    "main_df = main_df[[i for i in taxonID]]\n",
    "\n",
    "for i in range(20265):\n",
    "    f = open(\"uniprot-mapping/results/\"+str(gene_names.iloc[i,0])+\".id\", \"w\", newline='\\n')\n",
    "    for j in range(1, 12):\n",
    "        query = str(main_df.iloc[i,j])\n",
    "        if query==\"nan\":\n",
    "            pass\n",
    "        else:\n",
    "            query = query.split(\" \")\n",
    "            for k in query:\n",
    "                if k[0:2] == \"NP\":\n",
    "                    f.write(str(k)+\"\\n\")\n",
    "                else:\n",
    "                    f.write(str(k)+\"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "Entrez.email = \"corentin.meyer@etu.unistra.fr\"\n",
    "uni_gene_name = pd.read_csv(\"../refseq-long/Homo_sapiens.id\", sep=\"\\t\", header=None)\n",
    "\n",
    "##### Récupération du RefSeq ID à partir du Gene Name et de l'organisme d'intérêt\n",
    "myFetchList =  uni_gene_name.iloc[:,0].tolist()\n",
    "handle = Entrez.efetch(db=\"protein\", id=myFetchList, retmax=len(myFetchList), rettype=\"fasta\", retmode=\"text\")\n",
    "f = open(\"test.fasta\", \"w\")\n",
    "f.write(handle.read())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasta2List(pathFasta):\n",
    "    f = open(pathFasta, \"r\")\n",
    "    title = []\n",
    "    seq = []\n",
    "    seq_temp = []\n",
    "    for line in f:\n",
    "        if line[0] == \">\":\n",
    "            seq.append(''.join(seq_temp).replace(\"\\n\", \"\"))\n",
    "            title.append(line.replace(\"\\n\", \"\"))\n",
    "            seq_temp = []\n",
    "        else:\n",
    "            seq_temp.append(line)\n",
    "    seq.append(''.join(seq_temp).replace(\"\\n\", \"\"))\n",
    "    seq.pop(0)\n",
    "    return [title, seq]\n",
    "\n",
    "def FindNotFound(pathID):\n",
    "    f = open(pathID, \"r\")\n",
    "    myID = []\n",
    "    IDfile = pd.read_csv(pathID, sep=\"\\t\", header=None)\n",
    "    geneListID = IDfile.iloc[:,0].tolist()\n",
    "    for i, j in enumerate(geneListID):\n",
    "        if j == 'Not Found - Error':\n",
    "            myID.append(i)\n",
    "    return myID\n",
    "\n",
    "def AlterFasta(fastaPath, idPath):\n",
    "    t, s = fasta2List(fastaPath)\n",
    "    error = FindNotFound(idPath)\n",
    "    for i in error:\n",
    "        t.insert(i, \">NaN\")\n",
    "        s.insert(i, \"XXX\")\n",
    "    f = open(fastaPath+\".modified\", \"w\")\n",
    "    for i in range(len(t)):\n",
    "        f.write(t[i]+\"\\n\")\n",
    "        f.write(s[i]+\"\\n\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RefSeq-Long -> Line per file\n",
    "fullTable = pd.read_csv(\"../refseq-long/fulltable.csv\", sep=\"\\t\", header=None)\n",
    "fullTable.columns = [\"Homo\", \"Callithrix\", \"Gorilla\", \"Macaca1\", \"Pan\", \"Chlorocebus\", \"Nomascus\", \"Papio\", \"Macaca2\", \"Otolemu\", \"Pongo\"]\n",
    "\n",
    "for i in range(20071):\n",
    "    f = open(\"../refseq-long/results/\"+str(fullTable.iloc[i,0])+\".id\", \"w\", newline='\\n')\n",
    "    query = fullTable.iloc[i,:].tolist()\n",
    "    for i in query:\n",
    "        f.write(str(i)+\"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homo = fullTable.iloc[:,0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}